{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCLyD1xhb9X2"
      },
      "source": [
        "# How to test and visualise your agents.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCClqutxV1Xq"
      },
      "source": [
        "## Imports\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jKsFs6UfDWJG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mmi333/pragma/hacktrick-hackathon-2022/venv/lib/python3.8/site-packages/gym/envs/registration.py:595: UserWarning: \u001b[33mWARN: Overriding environment Hacktrick-v0\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {id}\")\n"
          ]
        }
      ],
      "source": [
        "from hacktrick_ai.src.hacktrick_ai_py.agents.benchmarking import AgentEvaluator, LayoutGenerator\n",
        "from hacktrick_ai.src.hacktrick_ai_py.visualization.state_visualizer import StateVisualizer\n",
        "from hacktrick_ai_py.agents.agent import AgentPair, StayAgent\n",
        "from hacktrick_agent import HacktrickAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM5MAxKLWEDa"
      },
      "source": [
        "## How to Run\n",
        "\n",
        "1. Set game mode to either single or collaborative.\n",
        "2. Set timesteps (We will be evaluating on 1200 timesteps).\n",
        "3. Set layout name.\n",
        "4. Create a HacktrickAgent instance, it will automatically include your algorith or RL agent if used from the `hacktrick_agent.py` file.\n",
        "5. Call run_agent() and pass the required parameters.\n",
        "6. run_agent() will return the trajectories of the played game.\n",
        "7. Call visualize() and pass the trajectories returned from running the agent to graphically view the game.\n",
        "\n",
        "(basically just run the notebook ;))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6bJJmpl_EsZU"
      },
      "outputs": [],
      "source": [
        "def run_agent(mode, timesteps, layout_name, hacktrick_agent):\n",
        "  hacktrick_agent.set_mode(mode)\n",
        "  if mode == 'collaborative':\n",
        "    agent0 = hacktrick_agent.agent0\n",
        "    agent1 = hacktrick_agent.agent1\n",
        "    agent = AgentPair(agent0, agent1)\n",
        "  elif mode == 'single':\n",
        "    agent0 = hacktrick_agent.agent0\n",
        "    agent1 = StayAgent()\n",
        "    agent = AgentPair(agent0, agent1)\n",
        "  mdp_gen_params = {\"layout_name\": layout_name}\n",
        "  mdp_fn = LayoutGenerator.mdp_gen_fn_from_dict(mdp_gen_params)\n",
        "  env_params = {\"horizon\": timesteps}\n",
        "  agent_eval = AgentEvaluator(env_params=env_params, mdp_fn=mdp_fn)\n",
        "  trajectories = agent_eval.evaluate_agent_pair(agent, num_games=1)\n",
        "  return trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WGYCS4fsQgk4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-19 13:47:53,256\tINFO resource_spec.py:204 -- Starting Ray with 11.38 GiB memory available for workers and up to 5.7 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2022-03-19 13:47:54,275\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
            "2022-03-19 13:47:54,431\tINFO trainer.py:578 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "/home/mmi333/pragma/hacktrick-hackathon-2022/venv/lib/python3.8/site-packages/ray/rllib/models/model.py:195: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  return tf.layers.flatten(obs)\n",
            "/home/mmi333/pragma/hacktrick-hackathon-2022/venv/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/home/mmi333/pragma/hacktrick-hackathon-2022/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py:322: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  SampleBatch.DONES: np.array([False], dtype=np.bool),\n",
            "/home/mmi333/pragma/hacktrick-hackathon-2022/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py:375: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  elif v.dtype == np.object:\n",
            "2022-03-19 13:48:02,108\tINFO trainable.py:217 -- Getting current IP.\n",
            "2022-03-19 13:48:02,111\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
            "2022-03-19 13:48:02,201\tINFO trainable.py:217 -- Getting current IP.\n",
            "2022-03-19 13:48:02,203\tINFO trainable.py:422 -- Restored on 192.168.0.109 from checkpoint: /home/mmi333/ray_results/PPO_leaderboard_single_True_nw=8_vf=0.000100_es=0.200000_en=0.010000_kl=0.200000_0_2022-03-19_12-43-13l_nhs3__/checkpoint_101/checkpoint-101\n",
            "2022-03-19 13:48:02,204\tINFO trainable.py:430 -- Current state after restoring: {'_iteration': 101, '_timesteps_total': 1212000, '_time_total': 2966.177577495575, '_episodes_total': 3030}\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing MotionPlanner to be saved in /home/mmi333/pragma/hacktrick-hackathon-2022/hacktrick_ai/src/hacktrick_ai_py/data/planners/leaderboard_single_mp.pkl\n",
            "It took 0.48938465118408203 seconds to create mp\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 1200.00; : 100%|██████████| 1/1 [00:04<00:00,  4.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping trajectory consistency checking because MDP was recognized as variable. Trajectory consistency checking is not yet supported for variable MDPs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Parameters to be changed\n",
        "\n",
        "mode = 'single'\n",
        "timesteps = 1200\n",
        "layout_name = 'cramped_room'\n",
        "agent = HacktrickAgent()\n",
        "trajectories = run_agent(mode, timesteps, layout_name, agent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CfmIXTEYJc_M"
      },
      "outputs": [],
      "source": [
        "def visualize(trajectories):\n",
        "  img_dir_path = StateVisualizer().display_rendered_trajectory(trajectories, trajectory_idx=0, ipython_display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UFaj9yXPVfuN"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21d69ff8509f4c8c91791554414a4cb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=1199), Output()), _dom_classes=('widget-i…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize(trajectories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hackathon-tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
